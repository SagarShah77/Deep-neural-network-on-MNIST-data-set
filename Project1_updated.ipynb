{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COL_NAMES': ['label', 'data'],\n",
       " 'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'target': array([ 0.,  0.,  0., ...,  9.,  9.,  9.])}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18403f08d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "some_digit = X[69999]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary,\n",
    "interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[69999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = X[:50000], X[50000:], y[:50000], y[50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle_index = np.random.permutation(50000)\n",
    "X2_train, y2_train = X2_train[shuffle_index], y_train[shuffle_index]\n",
    "X2_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Linear Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=20, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf2 = SGDClassifier(random_state=20)\n",
    "sgd_clf2.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1, ..., 4, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf2.predict(X2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09664647,  0.09695806,  0.09337494])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf2, X2_train, y2_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 4 6 ..., 8 1 7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred2 = cross_val_predict(sgd_clf2, X2_train, y2_train, cv=3)\n",
    "print(y_train_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[379  63 335 395 567 230 900 759 834 470]\n",
      " [476  70 369 452 688 268 979 869 935 572]\n",
      " [363  43 299 405 586 220 941 750 873 488]\n",
      " [405  33 356 409 598 252 935 752 873 488]\n",
      " [381  52 308 419 552 250 915 702 804 476]\n",
      " [363  61 308 378 548 195 806 656 744 447]\n",
      " [364  49 325 409 590 260 888 714 848 504]\n",
      " [393  52 375 418 648 257 912 768 850 502]\n",
      " [356  57 323 401 578 220 864 739 764 540]\n",
      " [381  51 364 415 641 230 942 686 819 459]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "sgd_conf_mx = confusion_matrix(y2_train, y_train_pred2)\n",
    "print (sgd_conf_mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRPhAQYQPFPRvWqa6gu5XrrMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1840592a198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(sgd_conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for 50000 sample training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:                precision    recall  f1-score   support\n",
      "\n",
      "          0       0.08      0.10      0.09      3861\n",
      "          1       0.01      0.13      0.02       531\n",
      "          2       0.06      0.09      0.07      3362\n",
      "          3       0.08      0.10      0.09      4101\n",
      "          4       0.11      0.09      0.10      5996\n",
      "          5       0.04      0.08      0.06      2382\n",
      "          6       0.18      0.10      0.13      9082\n",
      "          7       0.15      0.10      0.12      7395\n",
      "          8       0.16      0.09      0.12      8344\n",
      "          9       0.09      0.09      0.09      4946\n",
      "\n",
      "avg / total       0.12      0.10      0.10     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print ('Score:  ',(metrics.classification_report(y_train_pred2, y2_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data points: 47250\n",
      "validation data points: 5250\n",
      "testing data points: 17500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets\n",
    "from skimage import exposure\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import numpy as np\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist\n",
    " \n",
    "# take the MNIST data and construct the training and testing split, using 75% of the\n",
    "# data for training and 25% for testing\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(np.array(mnist.data),\n",
    "\tmnist.target, test_size=0.25, random_state=42)\n",
    " \n",
    "# now, let's take 10% of the training data and use that for validation\n",
    "(trainData, valData, trainLabels, valLabels) = train_test_split(trainData, trainLabels,\n",
    "\ttest_size=0.1, random_state=84)\n",
    "\n",
    "print(\"training data points: {}\".format(len(trainLabels)))\n",
    "print(\"validation data points: {}\".format(len(valLabels)))\n",
    "print(\"testing data points: {}\".format(len(testLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, accuracy=97.35%\n",
      "k=3, accuracy=97.68%\n",
      "k=5, accuracy=97.43%\n",
      "k=7, accuracy=97.28%\n",
      "k=9, accuracy=97.09%\n",
      "k=3 achieved highest accuracy of 97.68% on validation data\n"
     ]
    }
   ],
   "source": [
    "# initialize the values of k for our k-Nearest Neighbor classifier along with the\n",
    "# list of accuracies for each value of k\n",
    "kVals = range(1, 10, 2)\n",
    "accuracies = []\n",
    " \n",
    "# loop over various values of `k` for the k-Nearest Neighbor classifier\n",
    "for k in range(1, 10, 2):\n",
    "\t# train the k-Nearest Neighbor classifier with the current value of `k`\n",
    "\tmodelknn = KNeighborsClassifier(n_neighbors=k)\n",
    "\tmodelknn.fit(trainData, trainLabels)\n",
    " \n",
    "\t# evaluate the model and update the accuracies list\n",
    "\tscore = modelknn.score(valData, valLabels)\n",
    "\tprint(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
    "\taccuracies.append(score)\n",
    " \n",
    "# find the value of k that has the largest accuracy\n",
    "i = np.argmax(accuracies)\n",
    "print(\"k=%d achieved highest accuracy of %.2f%% on validation data\" % (kVals[i],\n",
    "\taccuracies[i] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION ON TESTING DATA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.99      0.98      1677\n",
      "        1.0       0.96      1.00      0.98      1935\n",
      "        2.0       0.98      0.97      0.98      1767\n",
      "        3.0       0.97      0.97      0.97      1766\n",
      "        4.0       0.97      0.97      0.97      1691\n",
      "        5.0       0.98      0.96      0.97      1653\n",
      "        6.0       0.98      0.99      0.98      1754\n",
      "        7.0       0.97      0.97      0.97      1846\n",
      "        8.0       0.98      0.94      0.96      1702\n",
      "        9.0       0.95      0.96      0.95      1709\n",
      "\n",
      "avg / total       0.97      0.97      0.97     17500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# re-train our classifier using the best k value and predict the labels of the\n",
    "# test data\n",
    "modelknn = KNeighborsClassifier(n_neighbors=kVals[i])\n",
    "modelknn.fit(trainData, trainLabels)\n",
    "predictions = modelknn.predict(testData)\n",
    " \n",
    "# show a final classification report demonstrating the accuracy of the classifier\n",
    "# for each of the digits\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(testLabels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5886,    4,    3,    0,    1,    6,   16,    2,    1,    4],\n",
       "       [   1, 6706,   11,    1,    2,    0,    3,   11,    1,    6],\n",
       "       [  43,   54, 5730,   12,   10,    5,    9,   79,   10,    6],\n",
       "       [   6,   19,   42, 5907,    1,   59,    5,   33,   35,   24],\n",
       "       [   9,   52,    1,    1, 5637,    0,   14,    9,    2,  117],\n",
       "       [  19,   14,    9,   68,    9, 5206,   56,    6,    9,   25],\n",
       "       [  25,   12,    1,    0,    8,   24, 5845,    0,    3,    0],\n",
       "       [   4,   57,   16,    3,   16,    1,    0, 6105,    1,   62],\n",
       "       [  26,   77,   37,   89,   32,   80,   22,   17, 5406,   65],\n",
       "       [  15,   15,    7,   41,   59,   12,    2,   74,    7, 5717]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_train_pred = cross_val_predict(modelknn, X_train, y_train, cv=3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1840595a278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_knnscores = cross_val_predict(modelknn, X_train, y_train_pred, cv=3)\n",
    "y_knnscores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Sample size = 60000 : 10000, Classifier = lbgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " One hidden layer neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Changed batch size, num_epochs, hidden size and activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.3607 - acc: 0.8964 - val_loss: 0.1862 - val_acc: 0.9503\n",
      "Epoch 2/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.1977 - acc: 0.9428 - val_loss: 0.1480 - val_acc: 0.9585\n",
      "Epoch 3/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.1411 - acc: 0.9592 - val_loss: 0.1100 - val_acc: 0.9697\n",
      "Epoch 4/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.1060 - acc: 0.9693 - val_loss: 0.0937 - val_acc: 0.9740\n",
      "Epoch 5/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0839 - acc: 0.9761 - val_loss: 0.0883 - val_acc: 0.9745\n",
      "Epoch 6/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0667 - acc: 0.9809 - val_loss: 0.0827 - val_acc: 0.9752\n",
      "Epoch 7/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0541 - acc: 0.9848 - val_loss: 0.0766 - val_acc: 0.9773\n",
      "Epoch 8/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0427 - acc: 0.9886 - val_loss: 0.0745 - val_acc: 0.9758\n",
      "Epoch 9/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0354 - acc: 0.9909 - val_loss: 0.0695 - val_acc: 0.9797\n",
      "Epoch 10/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0282 - acc: 0.9935 - val_loss: 0.0689 - val_acc: 0.9795\n",
      "Epoch 11/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0228 - acc: 0.9954 - val_loss: 0.0667 - val_acc: 0.9812\n",
      "Epoch 12/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0180 - acc: 0.9968 - val_loss: 0.0689 - val_acc: 0.9798\n",
      "Epoch 13/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0148 - acc: 0.9974 - val_loss: 0.0655 - val_acc: 0.9808\n",
      "Epoch 14/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0119 - acc: 0.9982 - val_loss: 0.0701 - val_acc: 0.9808\n",
      "Epoch 15/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0091 - acc: 0.9989 - val_loss: 0.0683 - val_acc: 0.9795\n",
      "Epoch 16/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0071 - acc: 0.9995 - val_loss: 0.0656 - val_acc: 0.9807\n",
      "Epoch 17/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0059 - acc: 0.9995 - val_loss: 0.0734 - val_acc: 0.9805\n",
      "Epoch 18/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0686 - val_acc: 0.9812\n",
      "Epoch 19/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0039 - acc: 0.9998 - val_loss: 0.0689 - val_acc: 0.9807\n",
      "Epoch 20/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0030 - acc: 0.9999 - val_loss: 0.0706 - val_acc: 0.9802\n",
      "Epoch 21/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0024 - acc: 0.9999 - val_loss: 0.0692 - val_acc: 0.9817\n",
      "Epoch 22/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0022 - acc: 0.9999 - val_loss: 0.0668 - val_acc: 0.9813\n",
      "Epoch 23/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0028 - acc: 0.9995 - val_loss: 0.0849 - val_acc: 0.9778\n",
      "Epoch 24/25\n",
      "54000/54000 [==============================] - 3s - loss: 0.0062 - acc: 0.9988 - val_loss: 0.0758 - val_acc: 0.9807\n",
      "Epoch 25/25\n",
      "54000/54000 [==============================] - 4s - loss: 0.0014 - acc: 0.9999 - val_loss: 0.0709 - val_acc: 0.9835\n",
      " 9120/10000 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.071374203202531128, 0.98129999999999995]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist # subroutines for fetching the MNIST dataset\n",
    "from keras.models import Model # basic class for specifying and training a neural network\n",
    "from keras.layers import Input, Dense # the two types of neural network layer we will be using\n",
    "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
    "\n",
    "batch_size = 130 # in each iteration, we consider 128 training examples at once\n",
    "num_epochs = 25 # we iterate twenty-five times over the entire training set\n",
    "hidden_size = 256 # there will be 256 neurons in both hidden layers\n",
    "\n",
    "num_train = 60000 # there are 60000 training examples in MNIST\n",
    "num_test = 10000 # there are 10000 test examples in MNIST\n",
    "\n",
    "height, width, depth = 28, 28, 1 # MNIST images are 28x28 and greyscale\n",
    "num_classes = 10 # there are 10 classes (1 per digit)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() # fetch MNIST data\n",
    "\n",
    "X_train = X_train.reshape(num_train, height * width) # Flatten data to 1D\n",
    "X_test = X_test.reshape(num_test, height * width) # Flatten data to 1D\n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255 # Normalise data to [0, 1] range\n",
    "X_test /= 255 # Normalise data to [0, 1] range\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels\n",
    "\n",
    "inp = Input(shape=(height * width,)) # Our input is a 1D vector of size 784\n",
    "hidden_1 = Dense(hidden_size, activation='tanh')(inp) # First hidden tanh layer\n",
    "\n",
    "out = Dense(num_classes, activation='softmax')(hidden_1) # Output softmax layer\n",
    "\n",
    "model_1hid = Model(inputs=inp, outputs=out) # To define a model, just specify its input and output layers\n",
    "\n",
    "model_1hid.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "\n",
    "model_1hid.fit(X_train, Y_train, # Train the model using the training set...\n",
    "          batch_size=batch_size, epochs=num_epochs,\n",
    "          verbose=1, validation_split=0.1) # ...holding out 10% of the data for validation\n",
    "\n",
    "Y_pred = model_1hid.predict(X_test)\n",
    "\n",
    "model_1hid.evaluate(X_test, Y_test, verbose=1) # Evaluate the trained model on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.96323152e-10   7.47175132e-15   4.22704982e-10 ...,   9.99998212e-01\n",
      "    3.41184214e-09   1.08265630e-09]\n",
      " [  8.11503642e-10   3.18931779e-05   9.99968052e-01 ...,   1.80929189e-16\n",
      "    1.73480661e-08   5.70463598e-13]\n",
      " [  5.89601645e-10   9.99986291e-01   1.08550466e-06 ...,   3.56213093e-07\n",
      "    1.20976465e-05   1.98610439e-09]\n",
      " ..., \n",
      " [  1.43452619e-14   1.14754762e-14   3.14173562e-15 ...,   2.77476673e-08\n",
      "    1.60267966e-09   2.93277882e-08]\n",
      " [  3.52300139e-13   3.33880140e-13   1.45971576e-14 ...,   2.10395416e-12\n",
      "    1.26945508e-06   2.54076138e-14]\n",
      " [  1.36736816e-10   1.26476251e-11   6.97557301e-09 ...,   1.85575991e-14\n",
      "    3.60529488e-12   3.67084141e-11]]\n",
      "[7 2 1 ..., 4 5 6]\n",
      "[[ 972    1    2    0    1    1    1    1    1    0]\n",
      " [   0 1125    4    0    0    1    2    1    2    0]\n",
      " [   2    0 1014    4    1    0    1    4    6    0]\n",
      " [   0    0    1  998    0    2    0    2    5    2]\n",
      " [   2    0    1    1  959    0    6    4    2    7]\n",
      " [   3    0    0    9    1  870    3    1    3    2]\n",
      " [   4    2    3    1    1    5  940    1    1    0]\n",
      " [   1    2    7    3    1    0    0 1007    5    2]\n",
      " [   3    0    6    5    1    3    2    4  949    1]\n",
      " [   2    2    1    6    7    2    0    6    4  979]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "Y_1hidpred2 = model_1hid.predict(X_test)\n",
    "print(Y_1hidpred2)\n",
    "y_pred1hid2 = np.argmax(Y_1hidpred2, axis=1)\n",
    "print(y_pred1hid2)\n",
    "hid1_conf_mx = confusion_matrix(np.argmax(Y_test,axis=1), y_pred1hid2)\n",
    "print(hid1_conf_mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACiVJREFUeJzt3c+LXfUdxvHnMaNoYlFDu8lMaIJU6w8okaGoARfGRVsl\nbrqwoFA32bQaRRDtxn9ARBdFGGLdKLqIgkWKWlAXdRE6JoKTjBWJNj/FlFAVN1HydDG34I/p3DP2\nfu+Zm8/7BYHM5OTw4XLfc849c+73OokA1HJe3wMAGD/CBwoifKAgwgcKInygIMIHCuotfNu/sP0P\n2x/YfqivObqyvdn2G7YP2T5oe3ffM3Vhe53tA7Zf7nuWLmxfanuv7fdsL9q+oe+ZhrF9/+A5sWD7\nOdsX9j3TML2Eb3udpD9K+qWkqyX9xvbVfcyyCl9JeiDJ1ZKul/S7CZhZknZLWux7iFV4QtIrSX4q\n6Wda47PbnpZ0r6TZJNdKWifpjn6nGq6vI/7PJX2Q5HCSM5Kel3R7T7N0kuRkkv2Dv3+upSfkdL9T\nrcz2jKRbJe3pe5YubF8i6SZJT0lSkjNJ/t3vVJ1MSbrI9pSk9ZJO9DzPUH2FPy3p6Ne+PqY1HtHX\n2d4iaZukff1OMtTjkh6UdLbvQTraKumUpKcHL0/22N7Q91ArSXJc0qOSjkg6KenTJK/1O9VwXNxb\nJdsXS3pB0n1JPut7nv/F9m2SPknydt+zrMKUpOskPZlkm6QvJK3p6z+2L9PS2epWSZskbbB9Z79T\nDddX+Mclbf7a1zOD761pts/XUvTPJnmx73mG2C5pp+2PtPRS6mbbz/Q70lDHJB1L8t8zqb1a+kGw\nlt0i6cMkp5J8KelFSTf2PNNQfYX/d0k/sb3V9gVauhjy555m6cS2tfTaczHJY33PM0ySh5PMJNmi\npcf39SRr+kiU5GNJR21fOfjWDkmHehypiyOSrre9fvAc2aE1fkFSWjq1GrskX9n+vaRXtXQV9E9J\nDvYxyypsl3SXpHdtvzP43h+S/KXHmc5F90h6dnBAOCzp7p7nWVGSfbb3Stqvpd/8HJA01+9Uw5m3\n5QL1cHEPKIjwgYIIHyiI8IGCCB8oqPfwbe/qe4bVmLR5JWYeh0mbt/fwJU3UA6bJm1di5nGYqHnX\nQvgAxqzJDTwbN27M9HS3N9udPn1aGzdu7LTtwsLC/zMWUEISD9umyS2709PTeumll0a+38svv3zk\n+wQq4lQfKIjwgYIIHyiI8IGCCB8oqFP4k7YGPoCVDQ1/QtfAB7CCLkf8iVsDH8DKuoQ/0WvgA/iu\nkV3cs73L9rzt+dOnT49qtwAa6BJ+pzXwk8wlmU0y2/XeewD96BL+xK2BD2BlQ9+kM6Fr4ANYQad3\n5w0+NIIPjgDOEdy5BxRE+EBBhA8URPhAQYQPFNRksU3bTT6Ct+Un+y59tDkw+bostskRHyiI8IGC\nCB8oiPCBgggfKIjwgYIIHyiI8IGCCB8oiPCBgggfKIjwgYIIHyiI8IGCCB8oiPCBgggfKIjwgYII\nHyiI8IGCCB8oiPCBgjp9aOZa0XIJ7BMnTjTZ76ZNm5rsF+PR8jnXcrn4YTjiAwURPlAQ4QMFET5Q\nEOEDBRE+UBDhAwUNDd/2Zttv2D5k+6Dt3eMYDEA7XW7g+UrSA0n22/6BpLdt/zXJocazAWhk6BE/\nyckk+wd//1zSoqTp1oMBaGdVr/Ftb5G0TdK+FsMAGI/O9+rbvljSC5LuS/LZMv++S9KuEc4GoBF3\neaOA7fMlvSzp1SSPddi+v3cffE+8SQfLmcQ36SQZOnSXq/qW9JSkxS7RA1j7urzG3y7pLkk3235n\n8OdXjecC0NDQ1/hJ/iap3fkOgLHjzj2gIMIHCiJ8oCDCBwoifKCgTjfwrHqnE3gDTytHjx5ttu/N\nmzc32zeWlL2BB8C5h/CBgggfKIjwgYIIHyiI8IGCCB8oiPCBgggfKIjwgYIIHyiI8IGCCB8oiPCB\ngggfKIjwgYIIHyiI8IGCCB8oiPCBgggfKIjwgYJYXnuCvf/++032e8UVVzTZ7yQuVd1Si8cjCctr\nA1ge4QMFET5QEOEDBRE+UBDhAwURPlBQ5/Btr7N9wPbLLQcC0N5qjvi7JS22GgTA+HQK3/aMpFsl\n7Wk7DoBx6HrEf1zSg5LONpwFwJgMDd/2bZI+SfL2kO122Z63PT+y6QA00eWIv13STtsfSXpe0s22\nn/n2RknmkswmmR3xjABGbGj4SR5OMpNki6Q7JL2e5M7mkwFoht/jAwVNrWbjJG9KerPJJADGhiM+\nUBDhAwURPlAQ4QMFET5QEKvsNnbeee1+tp492+YO6rfeeqvJfrdv395kv/gmVtkFsCzCBwoifKAg\nwgcKInygIMIHCiJ8oCDCBwoifKAgwgcKInygIMIHCiJ8oCDCBwoifKAgwgcKInygIMIHCiJ8oCDC\nBwoifKAgVtnFd9hDF2n9XhYWFprsV5KuueaaZvueNKyyC2BZhA8URPhAQYQPFET4QEGEDxRE+EBB\nncK3fantvbbfs71o+4bWgwFoZ6rjdk9IeiXJr21fIGl9w5kANDY0fNuXSLpJ0m8lKckZSWfajgWg\npS6n+lslnZL0tO0DtvfY3tB4LgANdQl/StJ1kp5Msk3SF5Ie+vZGtnfZnrc9P+IZAYxYl/CPSTqW\nZN/g671a+kHwDUnmkswmmR3lgABGb2j4ST6WdNT2lYNv7ZB0qOlUAJrqelX/HknPDq7oH5Z0d7uR\nALTWKfwk70jiFB44R3DnHlAQ4QMFET5QEOEDBRE+UBDhAwWxvPZAqyWlWzy++K7jx4832e/MzEyT\n/Urtnhssrw1gWYQPFET4QEGEDxRE+EBBhA8URPhAQYQPFET4QEGEDxRE+EBBhA8URPhAQYQPFET4\nQEGEDxRE+EBBhA8URPhAQYQPFET4QEGssjvQapXdlljBt73FxcVm+77qqqua7JdVdgEsi/CBgggf\nKIjwgYIIHyiI8IGCCB8oqFP4tu+3fdD2gu3nbF/YejAA7QwN3/a0pHslzSa5VtI6SXe0HgxAO11P\n9ackXWR7StJ6SSfajQSgtaHhJzku6VFJRySdlPRpktdaDwagnS6n+pdJul3SVkmbJG2wfecy2+2y\nPW97fvRjAhilLqf6t0j6MMmpJF9KelHSjd/eKMlcktkks6MeEsBodQn/iKTrba/30lvYdkhq95Yl\nAM11eY2/T9JeSfslvTv4P3ON5wLQ0FSXjZI8IumRxrMAGBPu3AMKInygIMIHCiJ8oCDCBwoifKCg\nTr/Oq6DVUtUtl+1ute9JXLa71WPRaglsSTp8+PDI97lz585O23HEBwoifKAgwgcKInygIMIHCiJ8\noCDCBwoifKAgwgcKInygIMIHCiJ8oCDCBwoifKAgwgcKInygIMIHCiJ8oCDCBwoifKAgwgcKcosV\nVW2fkvTPjpv/UNK/Rj5EO5M2r8TM47BW5v1xkh8N26hJ+Kthez7JbK9DrMKkzSsx8zhM2ryc6gMF\nET5Q0FoIf67vAVZp0uaVmHkcJmre3l/jAxi/tXDEBzBmhA8URPhAQYQPFET4QEH/AWqgbhZSdnkm\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1840595add8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(hid1_conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two hidden layer neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Changed batch_size, num_epochs, hidden_size and activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/25\n",
      "54000/54000 [==============================] - 5s - loss: 0.3119 - acc: 0.9073 - val_loss: 0.1474 - val_acc: 0.9585\n",
      "Epoch 2/25\n",
      "54000/54000 [==============================] - 4s - loss: 0.1470 - acc: 0.9556 - val_loss: 0.1181 - val_acc: 0.9643\n",
      "Epoch 3/25\n",
      "54000/54000 [==============================] - 5s - loss: 0.0996 - acc: 0.9692 - val_loss: 0.0843 - val_acc: 0.9753\n",
      "Epoch 4/25\n",
      "54000/54000 [==============================] - 4s - loss: 0.0729 - acc: 0.9780 - val_loss: 0.0821 - val_acc: 0.9762\n",
      "Epoch 5/25\n",
      "54000/54000 [==============================] - 4s - loss: 0.0564 - acc: 0.9821 - val_loss: 0.0812 - val_acc: 0.9768\n",
      "Epoch 6/25\n",
      "54000/54000 [==============================] - 5s - loss: 0.0423 - acc: 0.9869 - val_loss: 0.0660 - val_acc: 0.9798\n",
      "Epoch 7/25\n",
      "54000/54000 [==============================] - 4s - loss: 0.0323 - acc: 0.9907 - val_loss: 0.0712 - val_acc: 0.9808\n",
      "Epoch 8/25\n",
      "54000/54000 [==============================] - 4s - loss: 0.0244 - acc: 0.9928 - val_loss: 0.0759 - val_acc: 0.9775\n",
      "Epoch 9/25\n",
      "54000/54000 [==============================] - 4s - loss: 0.0180 - acc: 0.9949 - val_loss: 0.0611 - val_acc: 0.9830\n",
      "Epoch 10/25\n",
      "54000/54000 [==============================] - 4s - loss: 0.0134 - acc: 0.9966 - val_loss: 0.0775 - val_acc: 0.9777\n",
      "Epoch 11/25\n",
      "54000/54000 [==============================] - 4s - loss: 0.0108 - acc: 0.9974 - val_loss: 0.0738 - val_acc: 0.9805\n",
      "Epoch 12/25\n",
      "54000/54000 [==============================] - 4s - loss: 0.0074 - acc: 0.9984 - val_loss: 0.0767 - val_acc: 0.9813\n",
      "Epoch 13/25\n",
      "54000/54000 [==============================] - 4s - loss: 0.0055 - acc: 0.9988 - val_loss: 0.0754 - val_acc: 0.9813\n",
      "Epoch 14/25\n",
      "54000/54000 [==============================] - 4s - loss: 0.0066 - acc: 0.9982 - val_loss: 0.0812 - val_acc: 0.9805\n",
      "Epoch 15/25\n",
      "54000/54000 [==============================] - 4s - loss: 0.0099 - acc: 0.9971 - val_loss: 0.0964 - val_acc: 0.9772\n",
      "Epoch 16/25\n",
      "54000/54000 [==============================] - 4s - loss: 0.0113 - acc: 0.9964 - val_loss: 0.0768 - val_acc: 0.9813\n",
      "Epoch 17/25\n",
      "54000/54000 [==============================] - 4s - loss: 0.0033 - acc: 0.9994 - val_loss: 0.0726 - val_acc: 0.9828\n",
      "Epoch 18/25\n",
      "54000/54000 [==============================] - 4s - loss: 0.0010 - acc: 0.9999 - val_loss: 0.0697 - val_acc: 0.9830\n",
      "Epoch 19/25\n",
      "54000/54000 [==============================] - 4s - loss: 4.8821e-04 - acc: 1.0000 - val_loss: 0.0731 - val_acc: 0.9830\n",
      "Epoch 20/25\n",
      "54000/54000 [==============================] - 5s - loss: 3.3782e-04 - acc: 1.0000 - val_loss: 0.0711 - val_acc: 0.9840\n",
      "Epoch 21/25\n",
      "54000/54000 [==============================] - 4s - loss: 2.5191e-04 - acc: 1.0000 - val_loss: 0.0721 - val_acc: 0.9832\n",
      "Epoch 22/25\n",
      "54000/54000 [==============================] - 4s - loss: 2.0881e-04 - acc: 1.0000 - val_loss: 0.0716 - val_acc: 0.9838\n",
      "Epoch 23/25\n",
      "54000/54000 [==============================] - 4s - loss: 1.7614e-04 - acc: 1.0000 - val_loss: 0.0728 - val_acc: 0.9838\n",
      "Epoch 24/25\n",
      "54000/54000 [==============================] - 4s - loss: 1.4729e-04 - acc: 1.0000 - val_loss: 0.0735 - val_acc: 0.9837cc:\n",
      "Epoch 25/25\n",
      "54000/54000 [==============================] - 4s - loss: 1.2373e-04 - acc: 1.0000 - val_loss: 0.0749 - val_acc: 0.9840\n",
      " 9696/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist # subroutines for fetching the MNIST dataset\n",
    "from keras.models import Model # basic class for specifying and training a neural network\n",
    "from keras.layers import Input, Dense # the two types of neural network layer we will be using\n",
    "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
    "\n",
    "batch_size = 130 # in each iteration, we consider 130 training examples at once\n",
    "num_epochs = 25 # we iterate twenty times over the entire training set\n",
    "hidden_size = 256 # there will be 256 neurons in both hidden layers\n",
    "\n",
    "num_train = 60000 # there are 60000 training examples in MNIST\n",
    "num_test = 10000 # there are 10000 test examples in MNIST\n",
    "\n",
    "height, width, depth = 28, 28, 1 # MNIST images are 28x28 and greyscale\n",
    "num_classes = 10 # there are 10 classes (1 per digit)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() # fetch MNIST data\n",
    "\n",
    "X_train = X_train.reshape(num_train, height * width) # Flatten data to 1D\n",
    "X_test = X_test.reshape(num_test, height * width) # Flatten data to 1D\n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255 # Normalise data to [0, 1] range\n",
    "X_test /= 255 # Normalise data to [0, 1] range\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels\n",
    "\n",
    "inp = Input(shape=(height * width,)) # Our input is a 1D vector of size 784\n",
    "hidden_1 = Dense(hidden_size, activation='tanh')(inp) # First hidden tanh layer\n",
    "hidden_2 = Dense(hidden_size, activation='tanh')(hidden_1) # Second hidden tanh layer\n",
    "out = Dense(num_classes, activation='softmax')(hidden_2) # Output softmax layer\n",
    "\n",
    "model2hid = Model(inputs=inp, outputs=out) # To define a model, just specify its input and output layers\n",
    "\n",
    "model2hid.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "\n",
    "model2hid.fit(X_train, Y_train, # Train the model using the training set...\n",
    "          batch_size=batch_size, epochs=num_epochs,\n",
    "          verbose=1, validation_split=0.1) # ...holding out 10% of the data for validation\n",
    "model2hid.evaluate(X_test, Y_test, verbose=1) # Evaluate the trained model on the test set!\n",
    "y_2hid = model2hid.predict(X_test) # Evaluate the trained model on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.09610929e-12   4.54231074e-14   3.23972862e-11 ...,   1.00000000e+00\n",
      "    6.64721611e-10   8.16807844e-10]\n",
      " [  8.52288726e-12   2.02034780e-08   1.00000000e+00 ...,   3.04520938e-18\n",
      "    1.59482288e-11   2.59788376e-14]\n",
      " [  7.84062225e-12   1.00000000e+00   1.36498786e-08 ...,   7.07367454e-09\n",
      "    4.20613482e-08   1.26824898e-10]\n",
      " ..., \n",
      " [  3.34844512e-15   4.86209776e-16   3.06362208e-16 ...,   5.11773823e-09\n",
      "    1.02946429e-09   3.10795301e-08]\n",
      " [  9.09099185e-13   4.02684613e-13   2.92317238e-16 ...,   3.24847130e-15\n",
      "    3.92954558e-09   1.85618922e-13]\n",
      " [  1.99131311e-09   2.37517313e-15   5.27918022e-11 ...,   5.02694864e-18\n",
      "    3.55299346e-10   5.78044882e-13]]\n",
      "[7 2 1 ..., 4 5 6]\n",
      "[[ 973    0    1    0    0    1    2    1    2    0]\n",
      " [   0 1126    2    0    0    1    2    1    3    0]\n",
      " [   3    0 1012    4    1    0    3    4    5    0]\n",
      " [   0    0    4  997    0    3    0    3    2    1]\n",
      " [   1    0    1    1  964    1    6    1    1    6]\n",
      " [   2    0    0    6    1  873    5    0    3    2]\n",
      " [   4    2    0    0    1    5  945    0    1    0]\n",
      " [   1    4    6    3    1    0    0 1005    1    7]\n",
      " [   1    0    2    3    4    3    2    4  953    2]\n",
      " [   2    2    0    4    8    4    0    6    0  983]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "y_2hid = model2hid.predict(X_test)\n",
    "print(y_2hid)\n",
    "y_2hid = np.argmax(y_2hid, axis=1)\n",
    "print(y_2hid)\n",
    "hid2_conf_mx = confusion_matrix(np.argmax(Y_test,axis=1), y_2hid)\n",
    "print(hid2_conf_mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACgpJREFUeJzt3c+LXfUdxvHnaUbRxKKGdpNJbIIEQxBKZCjqgAvjoq0S\nN11YUKib2bQaRRDt3yCiiyIMsW4UXUTBIkUtqIsihI6JYJJJUYzNTzElVMVNFJ8u5hasTueesfd7\nz9x83i8QMuPJ4cNl3jnnnjnne51EAGr5Qd8DABg/wgcKInygIMIHCiJ8oCDCBwrqLXzbP7f9d9sf\n2H6krzm6sr3F9pu2j9o+Yntv3zN1YXud7UO2X+l7li5sX2V7v+1jthdt39T3TMPYfnDwM3HY9vO2\nL+t7pmF6Cd/2Okl/kPQLSTsl/dr2zj5mWYWvJD2UZKekGyX9dgJmlqS9khb7HmIVnpT0apIdkn6q\nNT677WlJ90uaSXK9pHWS7up3quH6OuL/TNIHST5MckHSC5Lu7GmWTpKcTXJw8OfPtfQDOd3vVCuz\nvVnS7ZL29T1LF7avlHSLpKclKcmFJP/qd6pOpiRdbntK0npJZ3qeZ6i+wp+WdPIbX5/SGo/om2xv\nlbRL0oF+JxnqCUkPS/q670E62ibpnKRnBm9P9tne0PdQK0lyWtJjkk5IOivp0ySv9zvVcFzcWyXb\nV0h6UdIDST7re57/xfYdkj5J8k7fs6zClKQbJD2VZJekLySt6es/tq/W0tnqNkmbJG2wfXe/Uw3X\nV/inJW35xtebB99b02xfoqXon0vyUt/zDDEraY/tj7T0VupW28/2O9JQpySdSvKfM6n9WvqHYC27\nTdLxJOeSfCnpJUk39zzTUH2F/zdJ221vs32pli6G/KmnWTqxbS2991xM8njf8wyT5NEkm5Ns1dLr\n+0aSNX0kSvKxpJO2rxt8a7ekoz2O1MUJSTfaXj/4GdmtNX5BUlo6tRq7JF/Z/p2k17R0FfSPSY70\nMcsqzEq6R9J7tt8dfO/3Sf7c40wXo/skPTc4IHwo6d6e51lRkgO290s6qKXf/BySNN/vVMOZx3KB\neri4BxRE+EBBhA8URPhAQYQPFNR7+Lbn+p5hNSZtXomZx2HS5u09fEkT9YJp8uaVmHkcJmretRA+\ngDFrcgPPxo0bMz3d7WG78+fPa+PGjZ22PXz48P8zFlBCEg/bpsktu9PT03r55ZdHvt9rr7125PsE\nKuJUHyiI8IGCCB8oiPCBgggfKKhT+JO2Bj6AlQ0Nf0LXwAewgi5H/IlbAx/AyrqEP9Fr4AP4rpFd\n3LM9Z3vB9sL58+dHtVsADXQJv9Ma+Enmk8wkmel67z2AfnQJf+LWwAewsqEP6UzoGvgAVtDp6bzB\nh0bwwRHARYI794CCCB8oiPCBgggfKIjwgYKaLLZpu8lH8Lb8ZN+ljzYHJl+XxTY54gMFET5QEOED\nBRE+UBDhAwURPlAQ4QMFET5QEOEDBRE+UBDhAwURPlAQ4QMFET5QEOEDBRE+UBDhAwURPlAQ4QMF\nET5QEOEDBRE+UFCnD81cK1ougX3mzJkm+920aVOT/WI8Wv7MtVwufhiO+EBBhA8URPhAQYQPFET4\nQEGEDxRE+EBBQ8O3vcX2m7aP2j5ie+84BgPQTpcbeL6S9FCSg7Z/KOkd239JcrTxbAAaGXrET3I2\nycHBnz+XtChpuvVgANpZ1Xt821sl7ZJ0oMUwAMaj8736tq+Q9KKkB5J8tsz/n5M0N8LZADTiLg8K\n2L5E0iuSXkvyeIft+3v64HviIR0sZxIf0kkydOguV/Ut6WlJi12iB7D2dXmPPyvpHkm32n538N8v\nG88FoKGh7/GT/FVSu/MdAGPHnXtAQYQPFET4QEGEDxRE+EBBnW7gWfVOJ/AGnlZOnDjRbN/XXHNN\ns31jco3kBh4AFx/CBwoifKAgwgcKInygIMIHCiJ8oCDCBwoifKAgwgcKInygIMIHCiJ8oCDCBwoi\nfKAgwgcKInygIMIHCiJ8oCDCBwoifKAgwgcKYnntCfb+++832e/27dub7HcSP2u+pRavRxKW1waw\nPMIHCiJ8oCDCBwoifKAgwgcKInygoM7h215n+5DtV1oOBKC91Rzx90pabDUIgPHpFL7tzZJul7Sv\n7TgAxqHrEf8JSQ9L+rrhLADGZGj4tu+Q9EmSd4ZsN2d7wfbCyKYD0ESXI/6spD22P5L0gqRbbT/7\n7Y2SzCeZSTIz4hkBjNjQ8JM8mmRzkq2S7pL0RpK7m08GoBl+jw8UNLWajZO8JemtJpMAGBuO+EBB\nhA8URPhAQYQPFET4QEGsstvYJK4s+/bbbzfZ7+zsbJP9SpO5ym4rrLILYFmEDxRE+EBBhA8URPhA\nQYQPFET4QEGEDxRE+EBBhA8URPhAQYQPFET4QEGEDxRE+EBBhA8URPhAQYQPFET4QEGEDxRE+EBB\nrLKL72i1MvCRI0ea7FeSdu7c2Wzfk4ZVdgEsi/CBgggfKIjwgYIIHyiI8IGCCB8oqFP4tq+yvd/2\nMduLtm9qPRiAdqY6bvekpFeT/Mr2pZLWN5wJQGNDw7d9paRbJP1GkpJckHSh7VgAWupyqr9N0jlJ\nz9g+ZHuf7Q2N5wLQUJfwpyTdIOmpJLskfSHpkW9vZHvO9oLthRHPCGDEuoR/StKpJAcGX+/X0j8E\n/yXJfJKZJDOjHBDA6A0NP8nHkk7avm7wrd2SjjadCkBTXa/q3yfpucEV/Q8l3dtuJACtdQo/ybuS\nOIUHLhLcuQcURPhAQYQPFET4QEGEDxRE+EBBLK890GpJ6RavL77r5MmTTfa7ZcuWJvuV2vzMJWF5\nbQDLI3ygIMIHCiJ8oCDCBwoifKAgwgcKInygIMIHCiJ8oCDCBwoifKAgwgcKInygIMIHCiJ8oCDC\nBwoifKAgwgcKInygIMIHCmKVXWAFx44da7bvHTt2NNkvq+wCWBbhAwURPlAQ4QMFET5QEOEDBRE+\nUFCn8G0/aPuI7cO2n7d9WevBALQzNHzb05LulzST5HpJ6yTd1XowAO10PdWfknS57SlJ6yWdaTcS\ngNaGhp/ktKTHJJ2QdFbSp0lebz0YgHa6nOpfLelOSdskbZK0wfbdy2w3Z3vB9sLoxwQwSl1O9W+T\ndDzJuSRfSnpJ0s3f3ijJfJKZJDOjHhLAaHUJ/4SkG22vt21JuyUtth0LQEtd3uMfkLRf0kFJ7w3+\nznzjuQA0xPP4wAp4Hh/ARYPwgYIIHyiI8IGCCB8oiPCBgqb6HgDf39L9VKPX4le8rbV6LVr9yk2S\njh8/PvJ97tmzp9N2HPGBgggfKIjwgYIIHyiI8IGCCB8oiPCBgggfKIjwgYIIHyiI8IGCCB8oiPCB\ngggfKIjwgYIIHyiI8IGCCB8oiPCBgggfKIjwgYJafWjmOUn/6Lj5jyT9c+RDtDNp80rMPA5rZd6f\nJPnxsI2ahL8atheSzPQ6xCpM2rwSM4/DpM3LqT5QEOEDBa2F8Of7HmCVJm1eiZnHYaLm7f09PoDx\nWwtHfABjRvhAQYQPFET4QEGEDxT0b7oobhW4GWO+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1846f8e1a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(hid2_conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X shape (70000, 784)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "X, Y = mnist.data, mnist.target\n",
    "X = np.asarray( X, 'float32')\n",
    "# Scaling between 0 and 1\n",
    "X = (X - np.min(X, 0)) / (np.max(X, 0) + 0.0001)  # 0-1 scaling\n",
    "# Convert to binary images\n",
    "X = X > 0.5\n",
    "print ('Input X shape', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Here learning rate, batch size,n_iter and test_size are changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -95.45, time = 26.74s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -84.97, time = 29.63s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -81.70, time = 30.22s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -82.61, time = 29.88s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -80.45, time = 29.02s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -85.27, time = 29.79s\n",
      "Score:                precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.99      0.98       660\n",
      "        1.0       0.98      0.99      0.99       779\n",
      "        2.0       0.96      0.98      0.97       688\n",
      "        3.0       0.96      0.95      0.96       733\n",
      "        4.0       0.97      0.97      0.97       640\n",
      "        5.0       0.96      0.93      0.95       651\n",
      "        6.0       0.98      0.98      0.98       738\n",
      "        7.0       0.98      0.97      0.98       724\n",
      "        8.0       0.96      0.96      0.96       672\n",
      "        9.0       0.95      0.96      0.95       715\n",
      "\n",
      "avg / total       0.97      0.97      0.97      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "rbm = BernoulliRBM(n_components=200, learning_rate=0.03, batch_size=8, n_iter=6, verbose=True, random_state=None)\n",
    "sv = clf = svm.SVC(gamma=0.002, C=100.)\n",
    "clf = Pipeline(steps=[('rbm', rbm), ('clf', sv)])\n",
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split( X, y, test_size=0.1, random_state=0)\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "print ('Score:  ',(metrics.classification_report(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here training and test ratio is changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6727507958375005"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_mnist = DecisionTreeClassifier()\n",
    "a = tree_mnist.fit(X2_train,y2_train)\n",
    "tree_predictions = a.predict(X2_test)\n",
    "\n",
    "tree_mse = mean_squared_error(tree_predictions, y2_test)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 97 100  91  99 100  89 101 116  84 103]\n",
      " [118 128  89 120 117  93 110 117 108 135]\n",
      " [123 107  94 111 117  87  96  79 110 108]\n",
      " [100 112 108 107  92 109  87 106  96  93]\n",
      " [114 108 107  78  79  93 105  96  98 104]\n",
      " [ 77 103 100  84  91  73  91  92  84  97]\n",
      " [109 100  89  88  83  96  89 102 100 102]\n",
      " [ 94 135 108 117  80  86 104 102 115  87]\n",
      " [465 596 527 492 508 452 503 480 496 506]\n",
      " [749 793 810 734 577 660 604 685 619 727]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "dt_conf_mx = confusion_matrix(y2_test, tree_predictions)\n",
    "print(dt_conf_mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntx7O+ABGjPCBgggfKIjwgYIIHyjof6m/zpOfhj8xAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1840489b668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(dt_conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0996\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(tree_predictions, y2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf_train, Xf_test, yf_train, yf_test = X[:50000], X[50000:], y[:50000], y[50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle_index = np.random.permutation(50000)\n",
    "Xf_train, yf_train = Xf_train[shuffle_index], yf_train[shuffle_index]\n",
    "Xf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(Xf_train,yf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000,), (20000, 784))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rf_pred.shape , Xf_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60355\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_rf_pred = rf.predict(Xf_test)\n",
    "\n",
    "print(metrics.accuracy_score(y_rf_pred,yf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 969    1    0    0    0    4    5    1    0    0]\n",
      " [   0 1124    3    3    0    1    4    0    0    0]\n",
      " [   8    1  992    7    5    1    5   12    1    0]\n",
      " [   0    0    9  981    0    8    0   10    2    0]\n",
      " [   1    0    3    0  966    0    7    3    2    0]\n",
      " [   5    2    1   14    2  861    6    1    0    0]\n",
      " [   8    3    0    0    6    1  940    0    0    0]\n",
      " [   1    5   19    1    4    1    0  997    0    0]\n",
      " [  24   57   99  204  109  188   71   32 4241    0]\n",
      " [  53   39   72  208 5704  160   11  685   26    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "rf_conf_mx = confusion_matrix(yf_test, y_rf_pred)\n",
    "print (rf_conf_mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nT71GGE8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1840486bb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(rf_conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:                precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.99      0.95       980\n",
      "        1.0       0.91      0.99      0.95      1135\n",
      "        2.0       0.83      0.96      0.89      1032\n",
      "        3.0       0.69      0.97      0.81      1010\n",
      "        4.0       0.14      0.98      0.25       982\n",
      "        5.0       0.70      0.97      0.81       892\n",
      "        6.0       0.90      0.98      0.94       958\n",
      "        7.0       0.57      0.97      0.72      1028\n",
      "        8.0       0.99      0.84      0.91      5025\n",
      "        9.0       0.00      0.00      0.00      6958\n",
      "\n",
      "avg / total       0.53      0.60      0.55     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "\n",
    "print ('Score:  ',(metrics.classification_report(yf_test, y_rf_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((63000, 784), (20000,))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_rf_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xforest, yforest = mnist[\"data\"], mnist[\"target\"]\n",
    "Xforest.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
